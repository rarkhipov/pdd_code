{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import scale\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "from pandas.tseries.offsets import *\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "\n",
    "from pylab import rcParams\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 10, 8\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:97: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:98: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:99: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:101: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:102: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:107: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28min 32s, sys: 583 ms, total: 28min 32s\n",
      "Wall time: 28min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "flat = pd.read_csv('flat_fix.csv', parse_dates=['sale','date_salestart', 'date_settle','flat_startsale'])\n",
    "price = pd.read_csv('price.csv',encoding='cp1251',parse_dates=['datefrom','dateto','date_salestart'])\n",
    "status = pd.read_csv('status.csv',encoding='cp1251',parse_dates=['datefrom','dateto'])\n",
    "test = pd.read_csv('test.csv', parse_dates=['date1'],encoding='cp1251')\n",
    "train = pd.read_csv('train.csv', parse_dates=['date1'],encoding='cp1251')\n",
    "\n",
    "y = train.value\n",
    "\n",
    "train = train.drop(['value','id','start_square','plan_s','plan_m','plan_l','vid_0','vid_1','vid_2'], axis=1)\n",
    "test = test.drop(['id'], axis=1)\n",
    "\n",
    "columns = ['id_bulk', 'spalen', 'date1', 'price', 'mean_sq', 'mean_fl','month', 'month_cnt', 'objclass', 'roomcount', 'wall', 'area', 'vh_groups', 'kindergarten', 'school',\n",
    "           'hospital', 'phok', 'trainarea', 'carwash', 'stores', 'wheelchairs', 'conditioner', 'ventilation', 'elevator', 'garbage_col', 'cctv', 'u_parking', \n",
    "           'noauto_yard', 'auto_places', 'factory_zone', 'green_zone', 'to_kremlin', 'to_mall', 'to_sadoviy', 'to_bigroad', 'to_autocross', 'to_undeground_walk',\n",
    "           'to_factory', 'to_park', 'to_park_walk', 'u_station_ring', 'yard_area', 'dollar', 'mortgage', 'deposit1', 'deposit13', 'depostit3']\n",
    "\n",
    "train.columns = columns\n",
    "test.columns = columns\n",
    "\n",
    "train['value'] = y\n",
    "\n",
    "train = pd.concat([train, pd.get_dummies(train['objclass'],prefix='c')], axis=1)\n",
    "test = pd.concat([test, pd.get_dummies(test['objclass'],prefix='c')], axis=1)\n",
    "\n",
    "for i in ['wall', 'vh_groups','carwash', 'stores', 'wheelchairs', 'u_parking', 'noauto_yard']:\n",
    "    train[i] = train[i].replace('да', 1).replace('нет', 0)\n",
    "    test[i] = test[i].replace('да', 1).replace('нет', 0)\n",
    "    \n",
    "train = train.drop(['garbage_col','elevator','trainarea', 'objclass'], axis=1)\n",
    "test = test.drop(['garbage_col','elevator','trainarea', 'objclass'], axis=1)\n",
    "\n",
    "train = pd.concat([train, pd.get_dummies(train['month'],prefix='m')], axis=1).drop(['month'], axis=1)\n",
    "months = pd.concat([pd.get_dummies(test['month'],prefix='m'), pd.DataFrame(data = np.zeros((test.shape[0],9)),\\\n",
    "                columns = ['m_1','m_2','m_6','m_7','m_8','m_9','m_10','m_11','m_12'])], axis=1).sort_index(axis=1)\n",
    "test = pd.concat([test, months], axis=1).drop(['month'], axis=1)\n",
    "\n",
    "train['id_bulk_sp'] = train['id_bulk'].map(str)+'_'+train['spalen'].map(str)\n",
    "test['id_bulk_sp'] = test['id_bulk'].map(str)+'_'+test['spalen'].map(str)\n",
    "flat['id_bulk_sp'] = flat['bulk_id'].map(str)+'_'+flat['spalen'].astype(int).map(str)\n",
    "\n",
    "flat['otdelka'] = flat.apply(lambda x: 1 if x.otdelka not in ['Не производится', None] else 0, axis=1)\n",
    "\n",
    "train = pd.concat([train, pd.get_dummies(train['spalen'],prefix='sp')], axis=1)\n",
    "test = pd.concat([test, pd.get_dummies(test['spalen'],prefix='sp')], axis=1)\n",
    "\n",
    "# salestart = pd.to_datetime(pd.concat([test,train],ignore_index=False).reset_index(drop=True).groupby('id_bulk_sp')['date1'].min())\n",
    "salestart = pd.to_datetime(flat.reset_index(drop=True).groupby('id_bulk_sp')['flat_startsale'].min())\n",
    "train['dayfromstart'] = train.apply(lambda x: float((x['date1'] - salestart[x['id_bulk_sp']]).days), axis=1)\n",
    "test['dayfromstart'] = test.apply(lambda x: float((x['date1'] - salestart[x['id_bulk_sp']]).days), axis=1)\n",
    "\n",
    "flat.date_settle = flat.date_settle.fillna(flat.date_settle.min())\n",
    "train['daytosettle'] = train.apply(lambda x: float(( flat[flat.id_bulk_sp == x['id_bulk_sp']]['date_settle'].iloc[0] - x['date1']).days), axis=1)\n",
    "test['daytosettle'] = test.apply(lambda x: float(( flat[flat.id_bulk_sp == x['id_bulk_sp']]['date_settle'].iloc[0] - x['date1']).days), axis=1)\n",
    "\n",
    "test['flat_count'] = test.apply(lambda x: len(flat[flat.id_bulk_sp == x['id_bulk_sp']]), axis=1)\n",
    "train['flat_count'] = train.apply(lambda x: len(flat[flat.id_bulk_sp == x['id_bulk_sp']]), axis=1)\n",
    "\n",
    "test['flat_left'] = test.apply(lambda x: len(flat[(flat.id_bulk_sp == x['id_bulk_sp'])&(flat.sale >= x['date1'])]), axis=1) \n",
    "train['flat_left'] = train.apply(lambda x: len(flat[(flat.id_bulk_sp == x['id_bulk_sp'])&(flat.sale >= x['date1'])]), axis=1)\n",
    "\n",
    "def getasaled(x,df,period):\n",
    "    try:\n",
    "        t = df[(df.id_bulk_sp == x['id_bulk_sp'])&(df.date1 == x['date1'] - DateOffset(months=period))].sort_values('date1').iloc[0]['value']\n",
    "        return(t)\n",
    "    except:\n",
    "        return(None)\n",
    "    \n",
    "def getlastprice(x,df,period):\n",
    "    try:\n",
    "        t = df[(df.id_bulk_sp == x['id_bulk_sp'])&(df.date1 == x['date1'] - DateOffset(months=period))].sort_values('date1').iloc[0]['price']\n",
    "        return(t)\n",
    "    except:\n",
    "        return(None)\n",
    "\n",
    "##лаги продаж\n",
    "train['saledlastmonth'] = train.apply(lambda x: getasaled(x,train,1), axis=1)\n",
    "train['saledlast2month'] = train.apply(lambda x: getasaled(x,train,2), axis=1)\n",
    "train['saledlast3month'] = train.apply(lambda x: getasaled(x,train,3), axis=1)\n",
    "train['saledlast4month'] = train.apply(lambda x: getasaled(x,train,4), axis=1)\n",
    "train['saledlast5month'] = train.apply(lambda x: getasaled(x,train,5), axis=1)\n",
    "train['saledlast6month'] = train.apply(lambda x: getasaled(x,train,6), axis=1)\n",
    "\n",
    "test['saledlastmonth'] = test.apply(lambda x: getasaled(x,train,1), axis=1)\n",
    "test['saledlast2month'] = test.apply(lambda x: getasaled(x,train,2), axis=1)\n",
    "test['saledlast3month'] = test.apply(lambda x: getasaled(x,train,3), axis=1)\n",
    "test['saledlast4month'] = test.apply(lambda x: getasaled(x,train,4), axis=1)\n",
    "test['saledlast5month'] = test.apply(lambda x: getasaled(x,train,5), axis=1)\n",
    "test['saledlast6month'] = test.apply(lambda x: getasaled(x,train,6), axis=1)\n",
    "\n",
    "##лаги цен\n",
    "train['pricelastmonth'] = train.apply(lambda x: getlastprice(x,train,1), axis=1)\n",
    "train['pricelast2month'] = train.apply(lambda x: getlastprice(x,train,2), axis=1)\n",
    "train['pricelast3month'] = train.apply(lambda x: getlastprice(x,train,3), axis=1)\n",
    "train['pricelast4month'] = train.apply(lambda x: getlastprice(x,train,4), axis=1)\n",
    "train['pricelast5month'] = train.apply(lambda x: getlastprice(x,train,5), axis=1)\n",
    "train['pricelast6month'] = train.apply(lambda x: getlastprice(x,train,6), axis=1)\n",
    "\n",
    "test['pricelastmonth'] = test.apply(lambda x: getlastprice(x,pd.concat([train,test]),1), axis=1)\n",
    "test['pricelast2month'] = test.apply(lambda x: getlastprice(x,pd.concat([train,test]),2), axis=1)\n",
    "test['pricelast3month'] = test.apply(lambda x: getlastprice(x,pd.concat([train,test]),3), axis=1)\n",
    "test['pricelast4month'] = test.apply(lambda x: getlastprice(x,pd.concat([train,test]),4), axis=1)\n",
    "test['pricelast5month'] = test.apply(lambda x: getlastprice(x,pd.concat([train,test]),5), axis=1)\n",
    "test['pricelast6month'] = test.apply(lambda x: getlastprice(x,pd.concat([train,test]),6), axis=1)\n",
    "\n",
    "##лаги остатков\n",
    "\n",
    "train['prevcount'] = train.apply(lambda x: len(train[(train.date1 < x['date1'])&(train.id_bulk_sp == x['id_bulk_sp'])]), axis=1)\n",
    "test['prevcount'] = test.apply(lambda x: len(pd.concat([train,test])[(pd.concat([train,test]).date1 < x['date1'])\\\n",
    "                                                                     &(pd.concat([train,test]).id_bulk_sp == x['id_bulk_sp'])]), axis=1)\n",
    "\n",
    "train['otdelka'] = train.apply(lambda x: flat[flat.id_bulk_sp == x['id_bulk_sp']]['otdelka'].mean(), axis=1)\n",
    "train['balcon'] = train.apply(lambda x: flat[flat.id_bulk_sp == x['id_bulk_sp']]['balcon'].mean(), axis=1)\n",
    "test['otdelka'] = test.apply(lambda x: flat[flat.id_bulk_sp == x['id_bulk_sp']]['otdelka'].mean(), axis=1)\n",
    "test['balcon'] = test.apply(lambda x: flat[flat.id_bulk_sp == x['id_bulk_sp']]['balcon'].mean(), axis=1)\n",
    "\n",
    "euro = pd.read_csv('euro.csv',encoding='cp1251', sep=';')\n",
    "euro['Средний курс'] = euro['Средний курс'].str.replace(',','.').astype(float)\n",
    "euro['Месяц'] = pd.to_datetime(euro['Месяц'], errors='raise', dayfirst=True)\n",
    "train['euro'] = train.apply(lambda x: euro[euro['Месяц'] == x['date1']]['Средний курс'].values[0], axis=1)\n",
    "test['euro'] = test.apply(lambda x: euro[euro['Месяц'] == x['date1']]['Средний курс'].values[0], axis=1)\n",
    "\n",
    "trainfull = train\n",
    "testfull = test\n",
    "\n",
    "train = train.drop(['id_bulk_sp', 'date1', 'id_bulk', 'value'], axis=1)\n",
    "test = test.drop(['id_bulk_sp', 'date1', 'id_bulk'], axis=1)\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = pd.concat([flat,pd.get_dummies(flat.plan_size,prefix='plan')],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('testfull.csv', index=False)\n",
    "train.to_csv('trainfull.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add = pd.read_csv('train.csv',  usecols=['bulk_id', 'spalen', 'value'] ,encoding='cp1251')\n",
    "add_test = pd.read_csv('test.csv',  usecols=['bulk_id', 'spalen'] ,encoding='cp1251')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train.sort_index(axis=1)\n",
    "test1 = test.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postproccesing(output):\n",
    "    output.columns = ['id', 'value']\n",
    "    output.value = output.value.apply(lambda x: 0 if x<0 else x)\n",
    "    output['value'] = output.apply(lambda x: ((test.loc[x['id'],'mean_sq']*test.loc[x['id'],'flat_left']) \n",
    "                                              if x['value']>(test.loc[x['id'],'mean_sq']*test.loc[x['id'],'flat_left']) \n",
    "                                              else x['value']), axis=1)\n",
    "    df = pd.concat([testfull, output.value], axis=1)\n",
    "    df['max'] = df.mean_sq*df.flat_left\n",
    "    merged = pd.concat([df.groupby('id_bulk_sp')['value'].sum(),df.groupby('id_bulk_sp')['max'].mean()], axis=1)\n",
    "\n",
    "    koef = merged[merged.value>merged['max']]['max']/merged[merged.value>merged['max']]['value']\n",
    "    df['value'] = df.apply(lambda x: x['value'] if x['id_bulk_sp'] not in koef else x['value']*koef[x['id_bulk_sp']], axis=1)\n",
    "\n",
    "    output = pd.DataFrame(data = df.value).reset_index()\n",
    "    output.columns = ['id', 'value']\n",
    "#     output.to_csv('result.csv', index=False)\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dollar_month = train1.groupby(train_cat.date1).dollar.mean()\n",
    "dollar_month_test = test1.groupby(test_cat.date1).dollar.mean()\n",
    "dollar_month = pd.concat([dollar_month,\n",
    "dollar_month_test])\n",
    "\n",
    "dollar_month = dollar_month.reset_index()\n",
    "dollar_month = dollar_month.sort_values('date1')\n",
    "\n",
    "dollar_month.loc[:, 'dollar_-1'] = dollar_month.dollar.shift(1)\n",
    "dollar_month.loc[:, 'dollar_-2'] = dollar_month.dollar.shift(2)\n",
    "dollar_month.loc[:, 'dollar_-3'] = dollar_month.dollar.shift(3)\n",
    "dollar_month.loc[:, 'dollar_-4'] = dollar_month.dollar.shift(4)\n",
    "dollar_month.loc[:, 'dollar_-5'] = dollar_month.dollar.shift(5)\n",
    "\n",
    "dollar_month = dollar_month.drop('dollar', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = pd.concat([\n",
    "train1,\n",
    "train_cat.loc[:, ['date1']].merge(dollar_month, how='left', on='date1')\n",
    "    ], axis=1)\n",
    "\n",
    "test1 = pd.concat([\n",
    "test1,\n",
    "test_cat.loc[:, ['date1']].merge(dollar_month, how='left', on='date1')\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('xgb')\n",
    "clf = XGBRegressor(n_estimators=2000, learning_rate=0.01, gamma=3, subsample=0.8, \n",
    "                   colsample_bytree=0.9, max_depth=6, nthread=-1)\n",
    "clf.fit(train1.drop(['date1'], axis=1),y)\n",
    "pr = clf.predict(test1.drop(['date1'], axis=1))\n",
    "output = pd.DataFrame(data = pr).reset_index()\n",
    "output1_res = postproccesing(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1_res.to_csv('result_xgb_dollar_lags.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = pd.concat([add.loc[:, ['bulk_id']], train1],axis=1)\n",
    "test2 = pd.concat([add_test.loc[:, ['bulk_id']], test1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.in1d(train2.drop(['date1'], axis=1).columns, ['bulk_id', 'spalen']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('cat')\n",
    "cat = CatBoostRegressor(n_estimators=5000, l2_leaf_reg=8, learning_rate=0.015)\n",
    "cat.fit(train2.drop(['date1'], axis=1),y, [0,63])\n",
    "pr = cat.predict(test2.drop(['date1'], axis=1))\n",
    "output = pd.DataFrame(data = pr).reset_index()\n",
    "output2_res = postproccesing(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2_res.to_csv('result_cat_categorical_5000.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('lgb')\n",
    "gbm = lgb.LGBMRegressor(objective='regression',\n",
    "                        num_leaves=60,\n",
    "                        max_depth = 6,\n",
    "                        learning_rate=0.02,\n",
    "                        n_estimators=2000,\n",
    "                        gamma=3,\n",
    "                       nthread=-1)\n",
    "\n",
    "gbm.fit(train1.drop(['date1'], axis=1),y.values.reshape(-1))\n",
    "pr = gbm.predict(test1.drop(['date1'], axis=1))\n",
    "output = pd.DataFrame(data = pr).reset_index()\n",
    "output3_res = postproccesing(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output3_res.to_csv('result_lgb_3000.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparsion = pd.concat([output1_res.value, output2_res.value, output3_res.value], axis=1)\n",
    "comparsion.columns = ['xgb', 'cat', 'lgb']\n",
    "comparsion['mean1'] = ((7*comparsion.xgb + 7*comparsion.cat + 0*comparsion.lgb)/(7+7+0))\n",
    "comparsion['mean2'] = ((7*comparsion.xgb + 7*comparsion.cat + 1*comparsion.lgb)/(7+7+1))\n",
    "\n",
    "output = pd.DataFrame(data = comparsion['mean1']).reset_index()\n",
    "output.columns = ['id', 'value']\n",
    "output.to_csv('result_merge_categ_7_7_0_dollar_lag.csv', index=False)\n",
    "\n",
    "output = pd.DataFrame(data = comparsion['mean2']).reset_index()\n",
    "output.columns = ['id', 'value']\n",
    "output.to_csv('result_merge_categ_7_7_1_dollar_lag.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
