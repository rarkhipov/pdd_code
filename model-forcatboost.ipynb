{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import scale\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "from pandas.tseries.offsets import *\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "\n",
    "from pylab import rcParams\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 10, 8\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:83: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:84: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:85: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:86: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:87: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:88: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:93: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21min 59s, sys: 1.05 s, total: 22min\n",
      "Wall time: 22min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "flat = pd.read_csv('flat_fix.csv', parse_dates=['sale','date_salestart', 'date_settle','flat_startsale'])\n",
    "price = pd.read_csv('price.csv',encoding='cp1251',parse_dates=['datefrom','dateto','date_salestart'])\n",
    "status = pd.read_csv('status.csv',encoding='cp1251',parse_dates=['datefrom','dateto'])\n",
    "test = pd.read_csv('test.csv', parse_dates=['date1'],encoding='cp1251')\n",
    "train = pd.read_csv('train.csv', parse_dates=['date1'],encoding='cp1251')\n",
    "\n",
    "y = train.value\n",
    "\n",
    "train = train.drop(['value','id','start_square','plan_s','plan_m','plan_l','vid_0','vid_1','vid_2'], axis=1)\n",
    "test = test.drop(['id'], axis=1)\n",
    "\n",
    "columns = ['id_bulk', 'spalen', 'date1', 'price', 'mean_sq', 'mean_fl','month', 'month_cnt', 'objclass', 'roomcount', 'wall', 'area', 'vh_groups', 'kindergarten', 'school',\n",
    "           'hospital', 'phok', 'trainarea', 'carwash', 'stores', 'wheelchairs', 'conditioner', 'ventilation', 'elevator', 'garbage_col', 'cctv', 'u_parking', \n",
    "           'noauto_yard', 'auto_places', 'factory_zone', 'green_zone', 'to_kremlin', 'to_mall', 'to_sadoviy', 'to_bigroad', 'to_autocross', 'to_undeground_walk',\n",
    "           'to_factory', 'to_park', 'to_park_walk', 'u_station_ring', 'yard_area', 'dollar', 'mortgage', 'deposit1', 'deposit13', 'depostit3']\n",
    "\n",
    "train.columns = columns\n",
    "test.columns = columns\n",
    "\n",
    "train['value'] = y\n",
    "\n",
    "train = train.drop(['garbage_col','elevator','trainarea', 'objclass'], axis=1)\n",
    "test = test.drop(['garbage_col','elevator','trainarea', 'objclass'], axis=1)\n",
    "\n",
    "train['id_bulk_sp'] = train['id_bulk'].map(str)+'_'+train['spalen'].map(str)\n",
    "test['id_bulk_sp'] = test['id_bulk'].map(str)+'_'+test['spalen'].map(str)\n",
    "flat['id_bulk_sp'] = flat['bulk_id'].map(str)+'_'+flat['spalen'].astype(int).map(str)\n",
    "\n",
    "flat['otdelka'] = flat.apply(lambda x: 1 if x.otdelka not in ['Не производится', None] else 0, axis=1)\n",
    "\n",
    "# salestart = pd.to_datetime(pd.concat([test,train],ignore_index=False).reset_index(drop=True).groupby('id_bulk_sp')['date1'].min())\n",
    "salestart = pd.to_datetime(flat.reset_index(drop=True).groupby('id_bulk_sp')['flat_startsale'].min())\n",
    "train['dayfromstart'] = train.apply(lambda x: float((x['date1'] - salestart[x['id_bulk_sp']]).days), axis=1)\n",
    "test['dayfromstart'] = test.apply(lambda x: float((x['date1'] - salestart[x['id_bulk_sp']]).days), axis=1)\n",
    "\n",
    "flat.date_settle = flat.date_settle.fillna(flat.date_settle.min())\n",
    "train['daytosettle'] = train.apply(lambda x: float(( flat[flat.id_bulk_sp == x['id_bulk_sp']]['date_settle'].iloc[0] - x['date1']).days), axis=1)\n",
    "test['daytosettle'] = test.apply(lambda x: float(( flat[flat.id_bulk_sp == x['id_bulk_sp']]['date_settle'].iloc[0] - x['date1']).days), axis=1)\n",
    "\n",
    "test['flat_count'] = test.apply(lambda x: len(flat[flat.id_bulk_sp == x['id_bulk_sp']]), axis=1)\n",
    "train['flat_count'] = train.apply(lambda x: len(flat[flat.id_bulk_sp == x['id_bulk_sp']]), axis=1)\n",
    "\n",
    "test['flat_left'] = test.apply(lambda x: len(flat[(flat.id_bulk_sp == x['id_bulk_sp'])&(flat.sale >= x['date1'])]), axis=1) \n",
    "train['flat_left'] = train.apply(lambda x: len(flat[(flat.id_bulk_sp == x['id_bulk_sp'])&(flat.sale >= x['date1'])]), axis=1)\n",
    "\n",
    "def getasaled(x,df,period):\n",
    "    try:\n",
    "        t = df[(df.id_bulk_sp == x['id_bulk_sp'])&(df.date1 == x['date1'] - DateOffset(months=period))].sort_values('date1').iloc[0]['value']\n",
    "        return(t)\n",
    "    except:\n",
    "        return(None)\n",
    "    \n",
    "def getlastprice(x,df,period):\n",
    "    try:\n",
    "        t = df[(df.id_bulk_sp == x['id_bulk_sp'])&(df.date1 == x['date1'] - DateOffset(months=period))].sort_values('date1').iloc[0]['price']\n",
    "        return(t)\n",
    "    except:\n",
    "        return(None)\n",
    "\n",
    "##лаги продаж\n",
    "train['saledlastmonth'] = train.apply(lambda x: getasaled(x,train,1), axis=1)\n",
    "train['saledlast2month'] = train.apply(lambda x: getasaled(x,train,2), axis=1)\n",
    "train['saledlast3month'] = train.apply(lambda x: getasaled(x,train,3), axis=1)\n",
    "train['saledlast4month'] = train.apply(lambda x: getasaled(x,train,4), axis=1)\n",
    "train['saledlast5month'] = train.apply(lambda x: getasaled(x,train,5), axis=1)\n",
    "train['saledlast6month'] = train.apply(lambda x: getasaled(x,train,6), axis=1)\n",
    "\n",
    "test['saledlastmonth'] = test.apply(lambda x: getasaled(x,train,1), axis=1)\n",
    "test['saledlast2month'] = test.apply(lambda x: getasaled(x,train,2), axis=1)\n",
    "test['saledlast3month'] = test.apply(lambda x: getasaled(x,train,3), axis=1)\n",
    "test['saledlast4month'] = test.apply(lambda x: getasaled(x,train,4), axis=1)\n",
    "test['saledlast5month'] = test.apply(lambda x: getasaled(x,train,5), axis=1)\n",
    "test['saledlast6month'] = test.apply(lambda x: getasaled(x,train,6), axis=1)\n",
    "\n",
    "##лаги цен\n",
    "train['pricelastmonth'] = train.apply(lambda x: getlastprice(x,train,1), axis=1)\n",
    "train['pricelast2month'] = train.apply(lambda x: getlastprice(x,train,2), axis=1)\n",
    "train['pricelast3month'] = train.apply(lambda x: getlastprice(x,train,3), axis=1)\n",
    "train['pricelast4month'] = train.apply(lambda x: getlastprice(x,train,4), axis=1)\n",
    "train['pricelast5month'] = train.apply(lambda x: getlastprice(x,train,5), axis=1)\n",
    "train['pricelast6month'] = train.apply(lambda x: getlastprice(x,train,6), axis=1)\n",
    "\n",
    "test['pricelastmonth'] = test.apply(lambda x: getlastprice(x,pd.concat([train,test]),1), axis=1)\n",
    "test['pricelast2month'] = test.apply(lambda x: getlastprice(x,pd.concat([train,test]),2), axis=1)\n",
    "test['pricelast3month'] = test.apply(lambda x: getlastprice(x,pd.concat([train,test]),3), axis=1)\n",
    "test['pricelast4month'] = test.apply(lambda x: getlastprice(x,pd.concat([train,test]),4), axis=1)\n",
    "test['pricelast5month'] = test.apply(lambda x: getlastprice(x,pd.concat([train,test]),5), axis=1)\n",
    "test['pricelast6month'] = test.apply(lambda x: getlastprice(x,pd.concat([train,test]),6), axis=1)\n",
    "\n",
    "##лаги остатков\n",
    "\n",
    "train['prevcount'] = train.apply(lambda x: len(train[(train.date1 < x['date1'])&(train.id_bulk_sp == x['id_bulk_sp'])]), axis=1)\n",
    "test['prevcount'] = test.apply(lambda x: len(pd.concat([train,test])[(pd.concat([train,test]).date1 < x['date1'])\\\n",
    "                                                                     &(pd.concat([train,test]).id_bulk_sp == x['id_bulk_sp'])]), axis=1)\n",
    "\n",
    "train['otdelka'] = train.apply(lambda x: flat[flat.id_bulk_sp == x['id_bulk_sp']]['otdelka'].mean(), axis=1)\n",
    "train['balcon'] = train.apply(lambda x: flat[flat.id_bulk_sp == x['id_bulk_sp']]['balcon'].mean(), axis=1)\n",
    "test['otdelka'] = test.apply(lambda x: flat[flat.id_bulk_sp == x['id_bulk_sp']]['otdelka'].mean(), axis=1)\n",
    "test['balcon'] = test.apply(lambda x: flat[flat.id_bulk_sp == x['id_bulk_sp']]['balcon'].mean(), axis=1)\n",
    "\n",
    "euro = pd.read_csv('euro.csv',encoding='cp1251', sep=';')\n",
    "euro['Средний курс'] = euro['Средний курс'].str.replace(',','.').astype(float)\n",
    "euro['Месяц'] = pd.to_datetime(euro['Месяц'], errors='raise', dayfirst=True)\n",
    "train['euro'] = train.apply(lambda x: euro[euro['Месяц'] == x['date1']]['Средний курс'].values[0], axis=1)\n",
    "test['euro'] = test.apply(lambda x: euro[euro['Месяц'] == x['date1']]['Средний курс'].values[0], axis=1)\n",
    "\n",
    "trainfull = train\n",
    "testfull = test\n",
    "\n",
    "train = train.drop(['id_bulk_sp', 'date1', 'id_bulk', 'value'], axis=1)\n",
    "test = test.drop(['id_bulk_sp', 'date1', 'id_bulk'], axis=1)\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = pd.concat([flat,pd.get_dummies(flat.plan_size,prefix='plan')],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfull.to_csv('testfull_cat.csv', index=False)\n",
    "trainfull.to_csv('trainfull_cat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = pd.read_csv('flat_fix.csv', parse_dates=['sale','date_salestart', 'date_settle','flat_startsale'])\n",
    "flat['id_bulk_sp'] = flat['bulk_id'].map(str)+'_'+flat['spalen'].astype(int).map(str)\n",
    "# salestart = pd.to_datetime(pd.concat([test,train],ignore_index=False).reset_index(drop=True).groupby('id_bulk_sp')['date1'].min())\n",
    "salestart = pd.to_datetime(flat.reset_index(drop=True).groupby('id_bulk_sp')['flat_startsale'].min())\n",
    "train['dayfromstart'] = trainfull.apply(lambda x: float((x['date1'] - salestart[x['id_bulk_sp']]).days), axis=1)\n",
    "test['dayfromstart'] = testfull.apply(lambda x: float((x['date1'] - salestart[x['id_bulk_sp']]).days), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199.24487007070823"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.2, random_state=1)\n",
    "# trainfull1 = X_train\n",
    "# X_train = X_train.drop(['id_bulk_sp', 'date1', 'id_bulk', 'value'], axis=1).reset_index(drop=True)\n",
    "# X_test = X_test.drop(['id_bulk_sp', 'date1', 'id_bulk'], axis=1).reset_index(drop=True)\n",
    "\n",
    "def postproccesing(output):\n",
    "    output.columns = ['id', 'value']\n",
    "    output.value = output.value.apply(lambda x: 0 if x<0 else x)\n",
    "#     output['value'] = output.apply(lambda x: ((X_test.loc[x['id'],'mean_sq']*X_test.loc[x['id'],'flat_left']) \n",
    "#                                               if x['value']>(X_test.loc[x['id'],'mean_sq']*X_test.loc[x['id'],'flat_left']) \n",
    "#                                               else x['value']), axis=1)\n",
    "#     df = pd.concat([testfull1, output.value], axis=1)\n",
    "#     df['max'] = df.mean_sq*df.flat_left\n",
    "#     merged = pd.concat([df.groupby('id_bulk_sp')['value'].sum(),df.groupby('id_bulk_sp')['max'].mean()], axis=1)\n",
    "\n",
    "#     koef = merged[merged.value>merged['max']]['max']/merged[merged.value>merged['max']]['value']\n",
    "#     df['value'] = df.apply(lambda x: x['value'] if x['id_bulk_sp'] not in koef else x['value']*koef[x['id_bulk_sp']], axis=1)\n",
    "\n",
    "#     output = pd.DataFrame(data = df.value).reset_index()\n",
    "#     output.columns = ['id', 'value']\n",
    "#     output.to_csv('result.csv', index=False)\n",
    "    return(output)\n",
    "\n",
    "clf = XGBRegressor(n_estimators=400, learning_rate=0.08, gamma=1, subsample=0.75, colsample_bytree=1, max_depth=6, nthread=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "pr = clf.predict(X_test)\n",
    "output1 = pd.DataFrame(data = pr).reset_index()\n",
    "# output1 = postproccesing(output)\n",
    "\n",
    "cat = CatBoostRegressor(logging_level='Silent',n_estimators=1500)\n",
    "cat.fit(X_train,y_train)\n",
    "pr = cat.predict(X_test)\n",
    "output2 = pd.DataFrame(data = pr).reset_index()\n",
    "# output2 = postproccesing(output)\n",
    "\n",
    "gbm = lgb.LGBMRegressor(objective='regression',\n",
    "                        num_leaves=80,\n",
    "                        max_depth = 6,\n",
    "                        learning_rate=0.03,\n",
    "                        n_estimators=2000,\n",
    "                       nthread=-1)\n",
    "\n",
    "gbm.fit(X_train,y_train)\n",
    "pr = gbm.predict(X_test)\n",
    "output3 = pd.DataFrame(data = pr).reset_index()\n",
    "\n",
    "# output3 = postproccesing(output)\n",
    "# df = pd.DataFrame(clf.feature_importances_,index=list(train.T.index))\n",
    "\n",
    "# %matplotlib inline\n",
    "# df[0].sort_values(ascending=False).plot(kind='bar',figsize=(20,10))\n",
    "\n",
    "comparsion = pd.concat([output1[0], output2[0], output3[0], y_test.reset_index(drop=True)], axis=1)\n",
    "comparsion.columns = ['xgb', 'cat', 'lgb', 'test']\n",
    "comparsion['differ_xgb'] = comparsion.xgb - comparsion.test\n",
    "comparsion['differ_cat'] = comparsion.cat - comparsion.test\n",
    "comparsion['differ_lgb'] = comparsion.lgb - comparsion.test\n",
    "comparsion['mean1'] = (comparsion.lgb*0.5+comparsion.xgb*0.5)\n",
    "comparsion['mean2'] = (comparsion.cat+comparsion.xgb+comparsion.lgb)/3\n",
    "# comparsion['differ_mean'] = abs(comparsion.mean2 - comparsion.test)\n",
    "\n",
    "np.sqrt(mean_squared_error(comparsion['mean2'], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparsion.sort_values('differ_ridge', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201.0973672120065"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(comparsion['mean2'], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparsion.loc[:,['mean2','test','differ_mean']].sort_values('differ_mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features : 67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "gbm = lgb.LGBMRegressor(objective='regression',\n",
    "                        num_leaves=80,\n",
    "                        max_depth = 6,\n",
    "                        learning_rate=0.03,\n",
    "                        n_estimators=2000, nthread=-1)\n",
    "# clf = XGBRegressor(n_estimators=400, learning_rate=0.08, gamma=1, subsample=0.75, colsample_bytree=1, max_depth=6, nthread=-1)\n",
    "# train1 = train.fillna(0)\n",
    "rfecv = RFECV(estimator=gbm, step=1, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "rfecv.fit(train1, y)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([309.06000606, 299.73298927, 267.40745136, 257.26557161,\n",
       "       243.34603692, 237.88662076, 228.89184035, 225.2179408 ,\n",
       "       223.4124908 , 222.5647934 , 220.45658921, 215.99582419,\n",
       "       214.8422561 , 213.24831611, 213.52338756, 214.82097166,\n",
       "       212.12681576, 212.06813053, 210.80674628, 211.07379585,\n",
       "       210.8382259 , 211.10700737, 210.58673501, 210.15359389,\n",
       "       209.42146513, 209.76038018, 210.27888672, 209.69068231,\n",
       "       210.75434351, 209.86404159, 210.85181186, 210.41475531,\n",
       "       210.41505425, 209.2707632 , 210.42240312, 209.72864849,\n",
       "       209.14795699, 209.30624742, 209.5912339 , 209.23851801,\n",
       "       208.80791985, 208.58696431, 208.44754903, 208.47718186,\n",
       "       208.85018539, 208.25802551, 208.44260822, 208.52279202,\n",
       "       208.60692869, 208.91552396, 208.89136432, 208.28058018,\n",
       "       208.94729614, 208.71346671, 208.90466326, 208.1928179 ,\n",
       "       208.51794935, 209.22585625, 208.46296791, 208.04442815,\n",
       "       208.43237193, 208.3201479 , 208.59548409, 208.69085464,\n",
       "       208.33163554, 208.55352512, 207.57828856, 207.77619652,\n",
       "       208.61516676, 208.32442253, 209.01515145, 208.97012879,\n",
       "       208.3967239 , 209.1876542 , 208.8068187 , 208.8068187 ,\n",
       "       208.8068187 , 208.8068187 , 208.8068187 ])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(abs(rfecv.grid_scores_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = rfecv.ranking_.tolist()\n",
    "names = train.T.index.tolist()\n",
    "ch = pd.DataFrame(data=ranks, columns=['ranks'])\n",
    "ch['names'] = names\n",
    "ch.sort_values('ranks', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laststatus = status.sort_values('datefrom').drop_duplicates(subset='id_flatwork', keep='last') \n",
    "laststatus.index = laststatus.id_flatwork\n",
    "laststatus = laststatus[laststatus.stat_name=='Реализован']\n",
    "\n",
    "sorteddates = pd.concat([flat, laststatus.datefrom], axis=1).loc[:,['date_settle','date_salestart','sale','datefrom']].dropna()\n",
    "\n",
    "sorteddates['diffe'] = abs(sorteddates['sale']-sorteddates['datefrom'])\n",
    "\n",
    "sorteddates[sorteddates.diffe>=pd.Timedelta('2 days')].sort_values('datefrom', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = pd.read_csv('flat.csv', parse_dates=['sale','date_salestart', 'date_settle'],encoding='cp1251')\n",
    "price = pd.read_csv('price.csv',encoding='cp1251',parse_dates=['datefrom','dateto','date_salestart'])\n",
    "# fixedsaledate = []\n",
    "notinstatus = []\n",
    "counter = 0\n",
    "maximum = flat.sort_values('sale',ascending=False).iloc[0]['sale']\n",
    "minimum = flat.sort_values('sale',ascending=True).iloc[0]['sale']\n",
    "def flatgreatagain(x):\n",
    "    global counter\n",
    "    counter+=1\n",
    "    if counter % 10000 == 0:\n",
    "        print(str(counter))\n",
    "    try:\n",
    "        laststatus = status[status.id_flatwork==x['id_flatwork']].sort_values('dateto').iloc[-1]\n",
    "    except:\n",
    "        notinstatus.append(x['id_flatwork'])\n",
    "        return(x['sale'])\n",
    "    if (x['sale'].date().strftime(\"%Y-%m\") == laststatus['datefrom'].date().strftime(\"%Y-%m\"))\\\n",
    "       &(laststatus['stat_name']=='Реализован'):\n",
    "        return(x['sale'])\n",
    "    else:\n",
    "        if laststatus['stat_name']=='Статус после покупки':\n",
    "            return(x['sale'])\n",
    "        elif laststatus['stat_name']=='Реализован':\n",
    "#             fixedsaledate.append(x['id_flatwork'])\n",
    "#             return(laststatus['datefrom'])\n",
    "            return(x['sale'])\n",
    "        elif laststatus['stat_name']=='Не реализуется':\n",
    "            listofstrange.append(x['id_flatwork'])\n",
    "            return(minimum)\n",
    "        else:\n",
    "            return(x['sale'])\n",
    "\n",
    "fixedsale = flat.apply(flatgreatagain, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "laststatus = status.sort_values('datefrom').drop_duplicates(subset=['id_flatwork'],keep='last').reset_index(drop=True).drop('stat', axis=1)\n",
    "flats = flat.loc[:,['id_flatwork','sale']].reset_index(drop=True)\n",
    "flats.index=flats.id_flatwork\n",
    "laststatus.index=laststatus.id_flatwork\n",
    "result = pd.concat([flats, laststatus], axis=1).dropna()\n",
    "result['differ'] = abs(result.datefrom-result.sale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "errors = result.drop('id_flatwork', axis=1).sort_values(['sale','differ'],ascending=False)\\\n",
    "[(result.stat_name=='Реализован')&(result['differ'] > pd.Timedelta('5 days'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.to_csv('errors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "startper = testfull.date1.min()\n",
    "test_first = testfull[testfull.date1==startper]\n",
    "test_second = testfull[testfull.date1==startper+DateOffset(months=1)]\n",
    "test_third = testfull[testfull.date1==startper+DateOffset(months=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_first['flat_left'] = test_first.apply(lambda x: len(flat[(flat.id_bulk_sp == x['id_bulk_sp'])&(flat.sale >= x['date1'])]), axis=1)\n",
    "test_first['saledlastmonth'] = test_first.apply(lambda x: len(flat[(flat.id_bulk_sp == x['id_bulk_sp'])&(flat.sale < x['date1'])&(flat.sale >= x['date1'] - DateOffset(months=1))]), axis=1)\n",
    "test_first['saledlast2month'] = test_first.apply(lambda x: len(flat[(flat.id_bulk_sp == x['id_bulk_sp'])&(flat.sale < x['date1'])&(flat.sale >= x['date1'] - DateOffset(months=2))]), axis=1)\n",
    "test_first['saledlast3month'] = test_first.apply(lambda x: len(flat[(flat.id_bulk_sp == x['id_bulk_sp'])&(flat.sale < x['date1'])&(flat.sale >= x['date1'] - DateOffset(months=3))]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_second['flat_left'] = test_first['flat_left'] - test_first['value']/test_first['mean_sq']\n",
    "test_second['saledlastmonth'] = test_first['value']/test_first['mean_sq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv', parse_dates=['date1'])\n",
    "test['id_bulk_sp'] = test['bulk_id'].map(str)+'_'+test['spalen'].map(str)\n",
    "test.apply(lambda x: x['price'] - test[(test.id_bulk_sp == x['id_bulk_sp'])&(test.date1 == (x['date1'] - DateOffset(months=1)))]['price'].get(0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear: 252.5586498556621\n",
      "RFReg: 218.6779725916835\n"
     ]
    }
   ],
   "source": [
    "train1 = train.fillna(0)\n",
    "linreg = LinearRegression()\n",
    "ridge = linear_model.Ridge(alpha = 0.5)\n",
    "rf = RandomForestRegressor(n_estimators=1000, criterion='mse', n_jobs=-1)\n",
    "print('Linear: '+str(np.sqrt(abs(np.mean(cross_val_score(linreg, train1, y, cv=cv, scoring='neg_mean_squared_error'))))))\n",
    "print('RFReg: '+str(np.sqrt(abs(np.mean(cross_val_score(rf, train1, y, cv=cv, scoring='neg_mean_squared_error'))))))\n",
    "# print('Ridge: '+str(np.sqrt(abs(np.mean(cross_val_score(ridge, train1, y, cv=cv, scoring='neg_mean_squared_error'))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210.15652154404563\n",
      "18.798876\n"
     ]
    }
   ],
   "source": [
    "train1 = train2.fillna(0)\n",
    "t = datetime.datetime.now()\n",
    "xgb = XGBRegressor(n_estimators=500, learning_rate=0.08, gamma=1, subsample=0.75, max_depth=6, nthread=-1, loss_function='RMSE', random_state=59)\n",
    "print(np.sqrt(abs(np.mean(cross_val_score(xgb, train1, y, cv=cv, scoring='neg_mean_squared_error',n_jobs=-1)))))\n",
    "print((datetime.datetime.now() - t).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train1.sort_index(axis=1)\n",
    "test1 = test1.sort_index(axis=1)\n",
    "\n",
    "def postproccesing(output):\n",
    "    output.columns = ['id', 'value']\n",
    "    output.value = output.value.apply(lambda x: 0 if x<0 else x)\n",
    "    output['value'] = output.apply(lambda x: ((test.loc[x['id'],'mean_sq']*test.loc[x['id'],'flat_left']) \n",
    "                                              if x['value']>(test.loc[x['id'],'mean_sq']*test.loc[x['id'],'flat_left']) \n",
    "                                              else x['value']), axis=1)\n",
    "    df = pd.concat([testfull, output.value], axis=1)\n",
    "    df['max'] = df.mean_sq*df.flat_left\n",
    "    merged = pd.concat([df.groupby('id_bulk_sp')['value'].sum(),df.groupby('id_bulk_sp')['max'].mean()], axis=1)\n",
    "\n",
    "    koef = merged[merged.value>merged['max']]['max']/merged[merged.value>merged['max']]['value']\n",
    "    df['value'] = df.apply(lambda x: x['value'] if x['id_bulk_sp'] not in koef else x['value']*koef[x['id_bulk_sp']], axis=1)\n",
    "\n",
    "    output = pd.DataFrame(data = df.value).reset_index()\n",
    "    output.columns = ['id', 'value']\n",
    "#     output.to_csv('result.csv', index=False)\n",
    "    return(output)\n",
    "\n",
    "clf = XGBRegressor(n_estimators=390, learning_rate=0.08, gamma=1, subsample=0.75, colsample_bytree=1, max_depth=5)\n",
    "clf.fit(train1,y)\n",
    "pr = clf.predict(test1)\n",
    "output = pd.DataFrame(data = pr).reset_index()\n",
    "output1 = postproccesing(output)\n",
    "\n",
    "cat = CatBoostRegressor(logging_level='Silent',n_estimators=1500)\n",
    "cat.fit(train1,y)\n",
    "pr = cat.predict(test1)\n",
    "output = pd.DataFrame(data = pr).reset_index()\n",
    "output2 = postproccesing(output)\n",
    "\n",
    "gbm = lgb.LGBMRegressor(objective='regression',\n",
    "                        num_leaves=80,\n",
    "                        max_depth = 6,\n",
    "                        learning_rate=0.03,\n",
    "                        n_estimators=2000)\n",
    "\n",
    "gbm.fit(train1,y)\n",
    "pr = gbm.predict(test1)\n",
    "output = pd.DataFrame(data = pr).reset_index()\n",
    "output3 = postproccesing(output)\n",
    "\n",
    "comparsion = pd.concat([output1.value, output2.value, output3.value], axis=1)\n",
    "comparsion.columns = ['xgb', 'cat', 'lgb']\n",
    "comparsion['mean1'] = (comparsion.cat*0.5+comparsion.xgb*0.5)\n",
    "comparsion['mean2'] = (comparsion.cat+comparsion.xgb+comparsion.lgb)/3\n",
    "output = pd.DataFrame(data = comparsion['mean2']).reset_index()\n",
    "output.columns = ['id', 'value']\n",
    "output.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(clf.feature_importances_,index=list(train.T.index))\n",
    "\n",
    "%matplotlib inline\n",
    "df[0].sort_values(ascending=False).plot(kind='bar',figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparsion = pd.concat([output1.value, output2.value, output3.value], axis=1)\n",
    "comparsion.columns = ['xgb', 'cat', 'lgb']\n",
    "comparsion['mean1'] = (comparsion.cat*0.5+comparsion.xgb*0.5)\n",
    "comparsion['mean2'] = (comparsion.cat+comparsion.xgb+comparsion.lgb)/3\n",
    "output = pd.DataFrame(data = comparsion['mean1']).reset_index()\n",
    "output.columns = ['id', 'value']\n",
    "output.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sort_index(axis=1)\n",
    "test = test.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(data = comparsion['mean2']).reset_index()\n",
    "output.columns = ['id', 'value']\n",
    "output.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "205.92 - LB 187.6409\n",
    "205.71 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor()\n",
    "cat = CatBoostRegressor(logging_level='Silent')\n",
    "parameters = { \n",
    "#               'min_child_weight': [1, 5, 10],\n",
    "#               'gamma': [0,0.5, 1, 1.5, 2, 5],\n",
    "#               'subsample': [0.6, 0.8, 1.0],\n",
    "#               'colsample_bytree': [0.6, 1, 1.2],\n",
    "#               'learning_rate':[0.02,0.06,0.10],\n",
    "              'n_estimators':[390,395,400],\n",
    "              'max_depth': [4,5]\n",
    "              }\n",
    "clf = GridSearchCV(xgb, parameters, scoring='neg_mean_squared_error', cv=cv,return_train_score=False, n_jobs=-1)\n",
    "clf.fit(train, y)\n",
    "gradresults = pd.DataFrame(clf.cv_results_)\n",
    "gradresults.sort_values('rank_test_score', axis=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = datetime.datetime.now()\n",
    "gbm = lgb.LGBMRegressor(objective='regression',\n",
    "                        num_leaves=80,\n",
    "                        max_depth = 12,\n",
    "                        learning_rate=0.05,\n",
    "                        n_estimators=400)                       \n",
    "print(np.sqrt(abs(np.mean(cross_val_score(gbm, train, y, cv=cv, scoring='neg_mean_squared_error')))))\n",
    "print((datetime.datetime.now() - t).total_seconds())\n",
    "\n",
    "t = datetime.datetime.now()\n",
    "cat = CatBoostRegressor(n_estimators=1500, logging_level='Silent')\n",
    "print(np.sqrt(abs(np.mean(cross_val_score(cat, train, y, cv=cv, scoring='neg_mean_squared_error')))))\n",
    "print((datetime.datetime.now() - t).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207.3920863516101\n",
      "110.311268\n"
     ]
    }
   ],
   "source": [
    "t = datetime.datetime.now()\n",
    "cat = CatBoostRegressor(n_estimators=2500, logging_level='Silent',loss_function='RMSE')\n",
    "print(np.sqrt(abs(np.mean(cross_val_score(cat, train, y, cv=cv, scoring='neg_mean_squared_error')))))\n",
    "print((datetime.datetime.now() - t).total_seconds())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
